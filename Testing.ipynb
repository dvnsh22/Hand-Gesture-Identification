{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db5fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from numpy import argmax\n",
    "from AppOpener import run\n",
    "from tensorflow.keras.models import load_model\n",
    "from screen_brightness_control import set_brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea246a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r'C:\\Users\\Development\\Desktop\\IEEE\\Model\\model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb7ca4",
   "metadata": {},
   "source": [
    "### Class for hand detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea913cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector :\n",
    "    def __init__(self) :\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(static_image_mode=False, max_num_hands=1,\n",
    "                                        min_detection_confidence=0.5,\n",
    "                                        min_tracking_confidence=0.5)\n",
    "        \n",
    "    # Function to return coordinates of detected hand, if any\n",
    "    def findHands(self, img, draw=True, flipType=True):\n",
    "\n",
    "            res = []\n",
    "\n",
    "            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            results = self.hands.process(imgRGB)\n",
    "            allHands = []\n",
    "            h, w, c = img.shape\n",
    "            if results.multi_hand_landmarks:\n",
    "                for handType, handLms in zip(results.multi_handedness, results.multi_hand_landmarks):\n",
    "\n",
    "                    # Landmark list\n",
    "                    mylmList = []\n",
    "                    xList = []\n",
    "                    yList = []\n",
    "                    for id, lm in enumerate(handLms.landmark):\n",
    "                        px, py, pz = int(lm.x * w), int(lm.y * h), int(lm.z * w)\n",
    "                        mylmList.append([px, py, pz])\n",
    "                        xList.append(px)\n",
    "                        yList.append(py)\n",
    "\n",
    "                    # Bounding box\n",
    "                    xmin, xmax = min(xList), max(xList)\n",
    "                    ymin, ymax = min(yList), max(yList)\n",
    "                    boxW, boxH = xmax - xmin, ymax - ymin\n",
    "                    bbox = xmin, ymin, boxW, boxH\n",
    "\n",
    "                    if draw:\n",
    "                        res.append(bbox)\n",
    "\n",
    "            if draw:\n",
    "                return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda7940f",
   "metadata": {},
   "source": [
    "### Performing OS operation based on gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b783fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 617ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "OPENING MEDIA PLAYER\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "OPENING MEDIA PLAYER\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "OPENING MEDIA PLAYER\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "No hand detected!\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "OPENING WORD\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "OPENING WORD\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "OPENING WORD\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "OPENING WORD\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "OPENING WORD\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "OPENING WORD\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "OPENING MEDIA PLAYER\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "OPENING MEDIA PLAYER\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "OPENING MEDIA PLAYER\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "OPENING WORD\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "OPENING WORD\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "No hand detected!\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "OPENING MEDIA PLAYER\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "OPENING MEDIA PLAYER\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "OPENING MEDIA PLAYER\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "OPENING MEDIA PLAYER\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "detector = Detector()\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    image = cv2.flip(image, 1)\n",
    "    hand_coor = detector.findHands(image)\n",
    "    \n",
    "    try :\n",
    "        if hand_coor:\n",
    "            for (x,y,w,h) in hand_coor:\n",
    "                cv2.rectangle(image,(x-20,y-20),(x+w+20,y+h+20),(0,255,255),2)\n",
    "                cropped_hand = image[y-20:y+h+20, x-20:x+w+20]\n",
    "                cropped_hand = cv2.resize(cropped_hand, (224,224))\n",
    "\n",
    "                ci = cv2.resize(cropped_hand,(224,224), interpolation = cv2.INTER_LINEAR)\n",
    "                ci = cropped_hand / 255.\n",
    "                ci = cropped_hand.reshape(1,224,224,3) \n",
    "                res = argmax(model.predict(ci), axis=1)\n",
    "\n",
    "                text = \"\"\n",
    "                if res[0] == 0:             # Closed palm\n",
    "                    set_brightness(25)\n",
    "                    text = \"Decreasing Brightness...\"\n",
    "                elif res[0] == 1:           # 5-finger\n",
    "                    set_brightness(100)\n",
    "                    text = \"Increasing Brightness...\"\n",
    "                elif res[0] == 2:           # 2-finger\n",
    "                    run(\"media player\")\n",
    "                    text = \"Launching Video Player...\"\n",
    "                elif res[0] == 3:           # 3-finger\n",
    "                    run(\"word\")\n",
    "                    text = \"Launching Word...\"\n",
    "                    \n",
    "                cv2.putText(image, text, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                    \n",
    "    except:\n",
    "            print(\"No hand detected!\")\n",
    "            \n",
    "    exit = cv2.waitKey(1)\n",
    "    \n",
    "    if exit == 13:\n",
    "        break\n",
    "    cv2.imshow(\"Hand Gesture Recognition\", image)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d762f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
